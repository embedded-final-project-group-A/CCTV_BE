import torch
import numpy as np
from ultralytics import YOLO
import cv2
import os
from datetime import datetime, timedelta

# ë””ë²„ê¹… ì„¤ì •
DEBUG = False

def debug_log(*args, **kwargs):
    if DEBUG:
        print(*args, **kwargs)

# ëª¨ë¸ ë¡œë“œ
model = YOLO("./yolo/best.pt")
names = model.names

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs("output/captures", exist_ok=True)
os.makedirs("output/clips", exist_ok=True)

# ë¹„ë””ì˜¤ ê²½ë¡œ ì„¤ì •
video_path = "videos/yolo_test.mp4"
cap = cv2.VideoCapture(video_path)

# í”„ë ˆì„ ì •ë³´
fps = cap.get(cv2.CAP_PROP_FPS)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# ë¶„ì„ êµ¬ê°„ ì„¤ì • (ì´ˆ ë‹¨ìœ„)
start_time_sec = 0   # ì˜ˆ: 0ì´ˆë¶€í„°
end_time_sec = 5     # ì˜ˆ: 5ì´ˆê¹Œì§€ ë¶„ì„

# ë¶„ì„ êµ¬ê°„ì˜ í”„ë ˆì„ ë²”ìœ„ ê³„ì‚°
start_frame = int(fps * start_time_sec)
end_frame = int(fps * end_time_sec)
if end_frame > total_frames:
    end_frame = total_frames

# í´ë¦½ ê¸¸ì´ ì„¤ì • (ì´ˆ ë‹¨ìœ„)
clip_duration = 2.0
half_clip_frames = int(fps * (clip_duration / 2))

# ì˜ìƒ ì‹œì‘ ì‹œê°„ (ê¸°ì¤€ ì‹œê°„, í•„ìš”ì‹œ ë³€ê²½)
video_start_time = datetime(2025, 5, 27, 12, 0, 0)

# ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
frame_count = 0
helmet_capture_count = 0
frames_buffer = []
buffer_start_frame_idx = 0  # frames_buffer[0]ì´ ì˜ìƒ ë‚´ ëª‡ ë²ˆì§¸ í”„ë ˆì„ì¸ì§€

# ë¡œê·¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
event_logs = []

# í´ë¦½ ì €ì¥ í•¨ìˆ˜
def save_clip(buffer, fps, output_path):
    if not buffer:
        return False
    height, width = buffer[0].shape[:2]
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    for f in buffer:
        out.write(f)
    out.release()
    return True

# íƒì§€ ê²°ê³¼ ì²˜ë¦¬ í•¨ìˆ˜ (ì €ì¥ ì‹œ ë¡œê·¸ ë°ì´í„° ë°˜í™˜)
def use_result(frame, results, current_idx):
    global helmet_capture_count
    captured = False

    if results and results[0].boxes is not None:
        bboxes = results[0].boxes.xyxy.cpu().numpy().astype(int)
        classes = results[0].boxes.cls.cpu().numpy().astype(int)
        pred_box = zip(classes, bboxes)

        for cls, bbox in pred_box:
            (x1, y1, x2, y2) = bbox
            label = names.get(cls, str(cls))
            debug_log(f"íƒì§€: í´ë˜ìŠ¤={label}, ìœ„ì¹˜=({x1},{y1})~({x2},{y2})")

            if label.lower() == "helmet" and not captured:
                # ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
                img_path = f"output/captures/helmet_capture_{helmet_capture_count}.jpg"
                img_saved = cv2.imwrite(img_path, frame)

                # í´ë¦½ ì €ì¥ ê²½ë¡œ ë° í´ë¦½ í”„ë ˆì„ ì¶”ì¶œ
                start = max(0, current_idx - half_clip_frames)
                end = min(len(frames_buffer), current_idx + half_clip_frames)
                clip_frames = frames_buffer[start:end]
                clip_path = f"output/clips/helmet_clip_{helmet_capture_count}.mp4"
                clip_saved = save_clip(clip_frames, fps, clip_path)

                if img_saved and clip_saved:
                    debug_log(f"[âœ… ì´ë¯¸ì§€ ì €ì¥ë¨] {img_path}")
                    debug_log(f"[ğŸï¸ í´ë¦½ ì €ì¥ë¨] {clip_path}")

                    # ì´ë²¤íŠ¸ ì‹œê°„ ê³„ì‚°
                    event_time = video_start_time + timedelta(seconds=frame_count / fps)
                    event_time_str = event_time.strftime("%Y-%m-%dT%H:%M:%S")

                    # URL ê²½ë¡œ (http í˜•ì‹)
                    image_url = f"https://localhost:8000/output/captures/helmet_capture_{helmet_capture_count}.jpg"
                    clip_url = f"https://localhost:8000/output/clips/helmet_clip_{helmet_capture_count}.mp4"

                    helmet_capture_count += 1
                    captured = True

                    # ë¡œê·¸ ë°ì´í„° ë°˜í™˜
                    return (event_time_str, image_url, clip_url)

                else:
                    debug_log(f"[âŒ ì €ì¥ ì‹¤íŒ¨] ì´ë¯¸ì§€: {img_saved}, í´ë¦½: {clip_saved}")

    return None

# ë©”ì¸ ë£¨í”„
while True:
    ret, frame = cap.read()
    if not ret:
        debug_log("ì˜ìƒ ë")
        break

    # í˜„ì¬ í”„ë ˆì„ì´ ë¶„ì„ êµ¬ê°„ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
    if frame_count < start_frame:
        frame_count += 1
        continue

    if frame_count > end_frame:
        debug_log("ë¶„ì„ ì¢…ë£Œ ì‹œê°„ ë„ë‹¬")
        break

    # ë²„í¼ì— í”„ë ˆì„ ì¶”ê°€
    frames_buffer.append(frame.copy())

    # ë²„í¼ ê¸¸ì´ ì œí•œ ë° ì‹œì‘ í”„ë ˆì„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    max_buffer_len = int(fps * 10)  # ìµœëŒ€ 10ì´ˆ ë¶„ëŸ‰ ë²„í¼ ìœ ì§€
    if len(frames_buffer) > max_buffer_len:
        frames_buffer.pop(0)
        buffer_start_frame_idx += 1

    results = model(frame, verbose=False)

    # í˜„ì¬ í”„ë ˆì„ì˜ ë²„í¼ ë‚´ ì¸ë±ìŠ¤ ê³„ì‚°
    current_buffer_idx = frame_count - buffer_start_frame_idx

    event_log = use_result(frame, results, current_buffer_idx)
    if event_log is not None:
        event_logs.append(event_log)
        print(f"[ì´ë²¤íŠ¸ ë¡œê·¸] Time: {event_log[0]}, Image URL: {event_log[1]}, Clip URL: {event_log[2]}")

    frame_count += 1

    if cv2.waitKey(1) == 27:  # ESC í‚¤ ì¢…ë£Œ
        break

cap.release()
cv2.destroyAllWindows()

print(f"ì´ {helmet_capture_count}ê°œì˜ í—¬ë©§ íƒì§€ ì´ë¯¸ì§€ì™€ í´ë¦½ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

# event_logs ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“  íƒì§€ ì´ë²¤íŠ¸ì˜ (ì‹œê°„, ì´ë¯¸ì§€ URL, í´ë¦½ URL) ì •ë³´ê°€ ë‹´ê²¨ ìˆìŒ
